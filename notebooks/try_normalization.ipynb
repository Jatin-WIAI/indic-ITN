{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_text_normalization.hi.run_predict import inverse_normalize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ['मुझे शून्य जुलाई लगे',\n",
    " 'मुझे दो महीने लगे',\n",
    " 'चार',\n",
    " 'सात',\n",
    " 'दो हजार दो सो पद्रह',\n",
    " 'तिन हजार छः सो पद्रह',\n",
    " 'तिन हजार आठ सो पद्रह',\n",
    " 'चार हजार एक सौ पद्रह',\n",
    " 'चार हजार आठ सौ पद्रह',\n",
    " 'पाच हजार पद्रह',\n",
    " 'पाच हजार नौ सो पद्रह',\n",
    " 'छः हजार नौ सौ पद्रह',\n",
    " 'आठ हजार सात सो पद्रह',\n",
    " 'नौ हजार पद्रह',\n",
    " 'नौ हजार चार सो पद्रह',\n",
    " 'शून्य दशमलव तिन बीघा जमीन है',\n",
    " 'शून्य दशमलव छः डिब्बा तेल',\n",
    " 'मुझे शून्य दशमलव सात घंटा लगे',\n",
    " 'शून्य दशमलव आठ बीघा खेत है',\n",
    " 'जमीन शून्य दशमलव नौ एकर',\n",
    " 'मैंने एक दशमलव तिन डिब्बा खाद उपयोग किया',\n",
    " 'मुझे एक दशमलव सात जुलाई लगे',\n",
    " 'मैंने दो दशमलव चार किलो बीज उपयोग किया',\n",
    " 'मैंने साढ़े दो ग्राम फ़र्टिलाइज़र उपयोग किया',\n",
    " 'साढ़े आठ']\n",
    "    \n",
    "output = inverse_normalize_text(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मुझे 0 जुलाई लगे  -----  मुझे शून्य जुलाई लगे\n",
      "मुझे दो महीने लगे  -----  मुझे दो महीने लगे\n",
      "4  -----  चार\n",
      "7  -----  सात\n",
      "2215  -----  दो हजार दो सो पद्रह\n",
      "3615  -----  तिन हजार छः सो पद्रह\n",
      "3815  -----  तिन हजार आठ सो पद्रह\n",
      "4115  -----  चार हजार एक सौ पद्रह\n",
      "4815  -----  चार हजार आठ सौ पद्रह\n",
      "5015  -----  पाच हजार पद्रह\n",
      "5915  -----  पाच हजार नौ सो पद्रह\n",
      "6915  -----  छः हजार नौ सौ पद्रह\n",
      "8715  -----  आठ हजार सात सो पद्रह\n",
      "9015  -----  नौ हजार पद्रह\n",
      "9415  -----  नौ हजार चार सो पद्रह\n",
      "0.3 बीघा जमीन है  -----  शून्य दशमलव तिन बीघा जमीन है\n",
      "0.6 डिब्बा तेल  -----  शून्य दशमलव छः डिब्बा तेल\n",
      "मुझे 0.7 घंटा लगे  -----  मुझे शून्य दशमलव सात घंटा लगे\n",
      "0.8 बीघा खेत है  -----  शून्य दशमलव आठ बीघा खेत है\n",
      "जमीन 0.9 एकर  -----  जमीन शून्य दशमलव नौ एकर\n",
      "मैंने 1.3 डिब्बा खाद उपयोग किया  -----  मैंने एक दशमलव तिन डिब्बा खाद उपयोग किया\n",
      "मुझे 1.7 जुलाई लगे  -----  मुझे एक दशमलव सात जुलाई लगे\n",
      "मैंने 2.4 किलो बीज उपयोग किया  -----  मैंने दो दशमलव चार किलो बीज उपयोग किया\n",
      "मैंने दो.5 ग्राम फ़र्टिलाइज़र उपयोग किया  -----  मैंने साढ़े दो ग्राम फ़र्टिलाइज़र उपयोग किया\n",
      "8  -----  साढ़े आठ\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(output,input):\n",
    "    print(i,\" ----- \",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_text_normalization.hi.taggers.cardinal import CardinalFst\n",
    "from inverse_text_normalization.hi.taggers.tokenize_and_classify_final import ClassifyFinalFst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynini.lib import pynutil\n",
    "import pynini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tagger= ClassifyFinalFst()\n",
    "\n",
    "def find_tags(text: str) -> 'pynini.FstLike':\n",
    "    \"\"\"\n",
    "    Given text use tagger Fst to tag text\n",
    "\n",
    "    Args:\n",
    "        text: sentence\n",
    "\n",
    "    Returns: tagged lattice\n",
    "    \"\"\"\n",
    "    lattice = text @ tagger.fst\n",
    "    return lattice\n",
    "\n",
    "\n",
    "def select_tag(lattice: 'pynini.FstLike') -> str:\n",
    "    \"\"\"\n",
    "    Given tagged lattice return shortest path\n",
    "\n",
    "    Args:\n",
    "        tagged_text: tagged text\n",
    "\n",
    "    Returns: shortest path\n",
    "    \"\"\"\n",
    "    tagged_text = pynini.shortestpath(lattice, nshortest=1, unique=True).string()\n",
    "    return tagged_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"दो\"\n",
    "# text = pynini.escape(text)\n",
    "tagged_lattice = find_tags(text)\n",
    "# print(\"tagged lattice is \", tagged_lattice)\n",
    "tagged_text = select_tag(tagged_lattice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tokens { name: \"दो\" }'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_verbalizer(tagged_text: str) -> 'pynini.FstLike':\n",
    "    \"\"\"\n",
    "    Given tagged text, e.g. token {name: \"\"} token {money {fractional: \"\"}}, creates verbalization lattice\n",
    "    This is context-independent.\n",
    "\n",
    "    Args:\n",
    "        tagged_text: input text\n",
    "\n",
    "    Returns: verbalized lattice\n",
    "    \"\"\"\n",
    "    lattice = tagged_text @ verbalizer.fst\n",
    "    return lattice\n",
    "\n",
    "\n",
    "def select_verbalizer(lattice: 'pynini.FstLike') -> str:\n",
    "    \"\"\"\n",
    "    Given verbalized lattice return shortest path\n",
    "\n",
    "    Args:\n",
    "        lattice: verbalization lattice\n",
    "\n",
    "    Returns: shortest path\n",
    "    \"\"\"\n",
    "    output = pynini.shortestpath(lattice, nshortest=1, unique=True).string()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_text_normalization.hi.verbalizers.verbalize_final import VerbalizeFinalFst\n",
    "verbalizer = VerbalizeFinalFst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मुझे दो महीने लगे\n"
     ]
    }
   ],
   "source": [
    "verbalizer_lattice = find_verbalizer(tagged_text)\n",
    "output = select_verbalizer(verbalizer_lattice)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_text_normalization.en.run_predict import inverse_normalize_text as en_inverse_normalize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['123']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_inverse_normalize_text([\"one hundred and twenty three\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indicitn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
